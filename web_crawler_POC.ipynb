{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# redundant and hacky implementation of BFS just to get some sample data\n",
    "- idea is to start at URL, then explore every link on page until depth is reached. \n",
    "- in dire need of refactoring, right now it has some major redundancies\n",
    "- note that links are only visited once to avoide cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def validate_url(driver, url):\n",
    "    ''' if valid url, return set (ie unique) of links otherwize return None'''\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        ids =  driver.find_elements_by_xpath('//*[@href]')\n",
    "        return set([x.get_attribute('href') for x in ids])\n",
    "    except:\n",
    "        return set()\n",
    "\n",
    "    \n",
    "def bfs(seed_url, driver, frames, limit):\n",
    "    ''' get all links from a given url'''\n",
    "    # set params for DF organization\n",
    "    depth = 0\n",
    "    node_id = 0\n",
    "    parent = 0\n",
    "    # dont repeat (endless cycles)\n",
    "    visited_set = set([seed_url])\n",
    "    #initilize seed row\n",
    "    frames[depth] = pd.DataFrame(dict(depth=[depth], node_id=[node_id], parent=[parent], url=[seed_url]))\n",
    "    depth += 1\n",
    "    # get links for seed\n",
    "    links = validate_url(driver, seed_url)\n",
    "    # remove ones that have been seen\n",
    "    links = links - visited_set\n",
    "    # used for unique identier of node for graphing\n",
    "    new_node_id = len(links) + node_id + 1\n",
    "    # build dataframe and append to list of frames\n",
    "    temp_frame = pd.DataFrame(dict(node_id=list(range(node_id + 1,new_node_id)), url=list(links)))\n",
    "    temp_frame['depth'] = depth\n",
    "    temp_frame['parent'] = parent\n",
    "    frames[depth] = (temp_frame)\n",
    "    #update node id\n",
    "    node_id = new_node_id - 1\n",
    "    # update visited set\n",
    "    visited_set.update(links)\n",
    "\n",
    "    for i in range(depth, limit):\n",
    "        depth += 1\n",
    "        temp_level = list()\n",
    "        for _,row in frames[i].iterrows():\n",
    "            links = validate_url(driver, row['url'])\n",
    "            links = links - visited_set\n",
    "            if len(links) > 0:\n",
    "                new_node_id = len(links) + node_id + 1\n",
    "                temp_frame = pd.DataFrame(dict(node_id=list(range(node_id + 1, new_node_id)), url=list(links)))\n",
    "                temp_frame['depth'] = depth\n",
    "                temp_frame['parent'] = row['node_id']\n",
    "                temp_level.append(temp_frame)\n",
    "                node_id = new_node_id - 1\n",
    "                visited_set.update(links)\n",
    "            \n",
    "        frames[depth] = pd.concat(temp_level)\n",
    "            \n",
    "    return pd.concat(frames.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at data from my website (not many links and still graph grows huge! )\n",
    "- just using my personal site bc I know it doesnt have a ton of links\n",
    "- could consider filtering link types (ie not getting resources files), this could be a simple as a regex for http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.set_page_load_timeout(10)\n",
    "frames = dict()\n",
    "tr = bfs(\"https://www.cas-donoghue.org/\", driver, frames, 2)\n",
    "\n",
    "driver.close()\n",
    "tr.to_csv(\"look.csv\")\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build node locations for visualization\n",
    "- can optimize here for sure, idea is to have everythin centered on x axis at 0\n",
    "- add columns that represent x and y coord of the nodes (urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_x_list(val):\n",
    "    '''spread x coord around 0'''\n",
    "    x = int(val/2)\n",
    "    if val%2 != 0:\n",
    "        return list(range(x*-1, x + 1))\n",
    "    else:\n",
    "        return list(range(x*-1, x))\n",
    "\n",
    "tr['node_y'] = tr['depth'] * -1\n",
    "count_series = tr['depth'].value_counts()\n",
    "index_dict = dict()\n",
    "y_col = list()\n",
    "\n",
    "for i,v in count_series.iteritems():\n",
    "    index_dict[i] = make_x_list(v)\n",
    "\n",
    "for key in sorted(index_dict.keys()):\n",
    "    y_col.extend(index_dict[key])\n",
    "tr['node_x'] = y_col\n",
    "  \n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build edge locations for visualizations\n",
    "- want the edges to be color coded by parent, implement as a multi-line glyph and turn off hover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import inferno\n",
    "# get coordinants for parent nodes\n",
    "parent_coords = dict()\n",
    "for i in tr['parent'].unique():\n",
    "    x = tr[tr['node_id'] == i]['node_x'].values[0]\n",
    "    y = tr[tr['node_id'] == i]['node_y'].values[0]\n",
    "    parent_coords[i] = (x,y)\n",
    "# color code lines\n",
    "colors = iter(inferno(len(parent_coords)))\n",
    "color_dict = dict()\n",
    "for key in parent_coords.keys():\n",
    "    color_dict[key] = next(colors)\n",
    "# get lists for edges\n",
    "all_x = list()\n",
    "all_y = list()\n",
    "edge_colors = list()\n",
    "for _,row in tr.iterrows():\n",
    "    pcoord_tuple = parent_coords[row['parent']]\n",
    "    all_x.append([row['node_x'], pcoord_tuple[0]])\n",
    "    all_y.append([row['node_y'], pcoord_tuple[1]])\n",
    "    edge_colors.append(color_dict[row['parent']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make one giant HTML file LOLOLOL\n",
    "- will have to refactor to make this way smaller, for now cram all resources (JS, CSS) into one giant HTML\n",
    "- for now getting a warning, will investigate later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, ColumnDataSource, output_file\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "\n",
    "output_file('dfs_mock.html')\n",
    "source = ColumnDataSource(data=dict(node_x=tr['node_x'], node_y=tr['node_y'], desc=tr['url']))\n",
    "\n",
    "hover = HoverTool(tooltips=[('URL', \"@desc\")], names=['nodes'])\n",
    "\n",
    "p = figure(plot_width=1200, plot_height=900, title=\"BFS prototype\")\n",
    "p.circle('node_x', 'node_y', name='nodes', size=5, source=source)\n",
    "p.multi_line(all_x, all_y, color=edge_colors, line_width=1)\n",
    "p.add_tools(hover)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
